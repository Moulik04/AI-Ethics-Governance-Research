# Locating Responsibility in Data Science: Can Ethics Be Outsourced?
### ğŸ“ Academic Research | AI Ethics & Governance

## ğŸ“Œ Executive Summary
This research critiques the growing tendency to "automate" ethical oversight within AI systems. Drawing on Leonelliâ€™s framework of distributed accountability, this paper argues that ethical judgment is a human-centered labor that cannot be delegated to machines without the total erosion of human agency.

## ğŸš€ Key Research Pillars
**The "Hallucination" of Confidence:** Analyzed how AI systems speak with authority in domains they are not qualified for, such as academic peer review, creating a "collective hallucination" of justified automation.
**Distributed Accountability:** Explored why accountability in data science is "distributed and fragile," making it easy for corporations to "shirk" ethics through technical compliance.
**The Gig Economy Case Study:** Investigated how opaque algorithms in the gig economy are used to displace moral responsibility from the employer to the system.

## ğŸ’¡ Core Insights
"The result is not ethical neutrality, but ethical erosion: where accountability is diffused, judgment is simulated, and responsibility quietly disappears."

**AI will not solve AI problems:** Automation cannot audit its own bias if the bias is embedded in the system's logic.
**Macro-Ethics over Technical Compliance:** Ethics must remain a human-centered interaction between data, algorithms, and social practices.

## ğŸ› ï¸ Frameworks Analyzed
**Sabina Leonelli:** "Locating Ethics in Data Science"
**Luciano Floridi:** "Five Risks of Being Unethical" & "What Is Data Ethics"
**Martin Heidegger:** Technological mode of thinking (Efficiency vs. Meaning)
